{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52e71b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mEDOF_CNN_pack()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "models.EDOF_CNN_pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63439acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.9686)\n",
      "tensor(0.)\n",
      "tensor(0.9216)\n",
      "tensor(0.)\n",
      "tensor(0.9020)\n",
      "tensor(0.)\n",
      "tensor(0.8039)\n",
      "tensor(0.)\n",
      "tensor(0.8824)\n",
      "tensor(0.)\n",
      "tensor(0.9137)\n",
      "tensor(0.)\n",
      "tensor(0.9176)\n",
      "tensor(0.)\n",
      "tensor(0.9137)\n",
      "tensor(0.)\n",
      "tensor(0.8980)\n",
      "tensor(0.)\n",
      "tensor(0.9529)\n",
      "tensor(0.)\n",
      "tensor(0.9843)\n",
      "tensor(0.)\n",
      "tensor(0.9529)\n",
      "tensor(0.)\n",
      "tensor(0.9804)\n",
      "tensor(0.)\n",
      "tensor(0.9725)\n",
      "tensor(0.)\n",
      "tensor(0.8902)\n",
      "tensor(0.)\n",
      "tensor(0.8980)\n",
      "tensor(0.)\n",
      "tensor(0.7647)\n",
      "tensor(0.)\n",
      "tensor(0.7294)\n",
      "tensor(0.)\n",
      "tensor(0.9608)\n",
      "tensor(0.)\n",
      "tensor(0.9529)\n",
      "tensor(0.)\n",
      "tensor(0.9686)\n",
      "tensor(0.)\n",
      "tensor(0.9922)\n",
      "tensor(0.)\n",
      "tensor(0.9373)\n",
      "tensor(0.)\n",
      "tensor(0.9647)\n",
      "tensor(0.)\n",
      "tensor(0.9020)\n",
      "tensor(0.)\n",
      "tensor(0.9176)\n",
      "tensor(0.)\n",
      "tensor(0.8980)\n",
      "tensor(0.)\n",
      "tensor(0.8471)\n",
      "tensor(0.)\n",
      "tensor(0.9804)\n"
     ]
    }
   ],
   "source": [
    "for XX, Y in tst:\n",
    "    print(Y.min())\n",
    "    print(Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad416269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_images(epochv):\n",
    "    Yhats=[]\n",
    "    Ytrues=[]\n",
    "    stacks=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for XX, Y in tst:\n",
    "              XX = [X.to(device) for X in XX]\n",
    "              Y = Y.to(device, torch.float)\n",
    "              Yhat = model(XX)\n",
    "              Yhats.append(Yhat[0].cpu().numpy())\n",
    "              Ytrues.append(Y[0].cpu().numpy())\n",
    "              stacks.append([z.cpu().numpy() for z in XX])\n",
    "              \n",
    "    from PIL import Image\n",
    "    from matplotlib import cm\n",
    "    \n",
    "    for i in range(3):\n",
    "        if args.epochs==200:\n",
    "            stack = stacks[i]\n",
    "            for s in range(args.Z):\n",
    "                stack0 = Image.fromarray(stack[s][0,0,:,:]* 255)\n",
    "                if stack0.mode != 'RGB':\n",
    "                    stack0 = stack0.convert('RGB')\n",
    "                stack0.save('teste_'+str(i)+'_stack_'+str(s)+'.png')\n",
    "        \n",
    "        x = np.moveaxis(Yhats[i], 0,2 )\n",
    "        xt = np.moveaxis(Ytrues[i], 0,2 )\n",
    "        x = x[:, :, 0]\n",
    "        xt = xt[:, :, 0]\n",
    "        # img = Image.fromarray(np.uint8(x*255), 'RGB')\n",
    "        img = Image.fromarray(x* 255)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        # img.save('image/teste'+str(i)+'_epoch_'+str(epochv)+'.png')\n",
    "        img.save('PRED_'+str(i)+'.png')\n",
    "        # imgt = Image.fromarray(np.uint8(xt*255), 'RGB')\n",
    "        imgt = Image.fromarray(xt* 255)\n",
    "        if imgt.mode != 'RGB':\n",
    "            imgt = imgt.convert('RGB')\n",
    "        imgt.save('GT_'+str(i)+'.png')\n",
    "\n",
    "\n",
    "\n",
    "def test(val):\n",
    "    model.eval()\n",
    "    avg_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for XX, Y in val:\n",
    "            XX = [X.to(device, torch.float) for X in XX]\n",
    "            Y = Y.to(device, torch.float)\n",
    "            Yhat = model(XX)\n",
    "            loss = model.loss(Yhat, Y.to(torch.float))\n",
    "            avg_loss_val += loss / len(val)\n",
    "    return avg_loss_val\n",
    "\n",
    "\n",
    "\n",
    "def train(tr, val, epochs=args.epochs, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        if verbose:\n",
    "            print(f'* Epoch {epoch+1}/{args.epochs}')\n",
    "        tic = time()\n",
    "        model.train()\n",
    "        avg_acc = 0\n",
    "        avg_loss = 0\n",
    "        for XX, Y in tr:\n",
    "            XX = [X.to(device, torch.float) for X in XX]\n",
    "            Y = Y.to(device, torch.float)\n",
    "            opt.zero_grad()\n",
    "            Yhat = model(XX)\n",
    "            loss = model.loss(Yhat, Y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            avg_loss += loss / len(tr)\n",
    "\n",
    "        dt = time() - tic\n",
    "        out = ' - %ds - Loss: %f' % (dt, avg_loss)\n",
    "        if val:\n",
    "            model.eval()\n",
    "            out += ', Test loss: %f' % test(val)\n",
    "        if verbose:\n",
    "            print(out)\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        #uncomment to see the examples\n",
    "        view_images(epoch)\n",
    "\n",
    "prefix = '-'.join(f'{k}-{v}' for k, v in vars(args).items())\n",
    "\n",
    "\n",
    "if args.method=='EDOF_CNN_max':\n",
    "    model = models.EDOF_CNN_max()\n",
    "elif args.method=='EDOF_CNN_3D':\n",
    "    model = models.EDOF_CNN_3D(args.Z)\n",
    "elif args.method=='EDOF_CNN_backbone':\n",
    "    model = models.EDOF_CNN_backbone()\n",
    "elif args.method=='EDOF_CNN_fast':\n",
    "    model = models.EDOF_CNN_fast()\n",
    "elif args.method=='EDOF_CNN_RGB':\n",
    "    model = models.EDOF_CNN_RGB()\n",
    "elif args.method=='EDOF_CNN_pairwise':\n",
    "    model = models.EDOF_CNN_pairwise()\n",
    "else: \n",
    "    model = models.EDOF_CNN_concat()\n",
    "\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load('results\\\\dataset-cervix93-image_size-512-method-EDOF_CNN_fast-Z-5-fold-0-epochs-200-batchsize-4-lr-0.001-cudan-1-image_channels-grayscale.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), args.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, verbose=True,patience=5)\n",
    "train(tr, ts)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), str(prefix)+'.pth')\n",
    "\n",
    "   \n",
    "#print some metrics \n",
    "def predict_metrics(data):\n",
    "    model.eval()\n",
    "    Phat = []\n",
    "    Y_true=[]\n",
    "    with torch.no_grad():\n",
    "        for XX, Y in data:\n",
    "            XX = [X.to(device, torch.float) for X in XX]\n",
    "            Y = Y.to(device, torch.float)\n",
    "            Yhat = model(XX)\n",
    "            Phat += list(Yhat.cpu().numpy())\n",
    "            Y_true += list(Y.cpu().numpy())\n",
    "    return Y_true, Phat\n",
    "\n",
    "\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio, normalized_root_mse \n",
    "\n",
    "\n",
    "data_test = DataLoader(ts_ds, 1,False,  pin_memory=True)\n",
    "Y_true, Phat = predict_metrics(data_test)\n",
    "\n",
    "mse = np.mean([mean_squared_error(Y_true[i], Phat[i]) for i in range(len(Y_true))])\n",
    "rmse = np.mean([normalized_root_mse(Y_true[i], Phat[i]) for i in range(len(Y_true))])\n",
    "ssim =np.mean([ssim(Y_true[i], Phat[i],channel_axis=0) for i in range(len(Y_true))]) \n",
    "psnr =np.mean([peak_signal_noise_ratio(Y_true[i], Phat[i]) for i in range(len(Y_true))]) \n",
    "\n",
    "\n",
    "\n",
    "f = open('results\\\\'+ str(prefix)+'.txt', 'a+')\n",
    "f.write('\\n\\nModel:'+str(prefix)+\n",
    "    ' \\nMSE:'+ str(mse)+\n",
    "    ' \\nRMSE:'+ str(rmse)+\n",
    "    ' \\nSSIM:'+str(ssim)+\n",
    "    ' \\nPSNR:'+ str(psnr))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# def test_cyto(path_f='test_data_aligned',img_size=640):\n",
    "#     cyto_ds = dataset.Dataset_folder(dataset.val_transforms, path_f , args.Z,img_size)\n",
    "#     cyto_ts = DataLoader(cyto_ds, 1 ,False,  pin_memory=True)\n",
    "#     model.eval()\n",
    "#     avg_loss_val = 0\n",
    "#     with torch.no_grad():\n",
    "#         for XX in tqdm(cyto_ts):\n",
    "#             print(XX)\n",
    "#             XX = [X.to(device, torch.float) for X in XX]\n",
    "#             Yhat = model(XX)\n",
    "#     final_edf=Yhat.cpu().numpy()\n",
    "#     img=Image.fromarray(final_edf[0,0,:,:]* 255)\n",
    "#     if img.mode != 'RGB':\n",
    "#         img = img.convert('RGB')\n",
    "#     img.save('teste_cyto.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
